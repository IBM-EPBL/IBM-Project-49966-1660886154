{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "!pip install Keras==2.2.4\n!pip install tensorflow==2.7",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Requirement already satisfied: Keras==2.2.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.2.4)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (3.2.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (1.1.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (1.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (5.4.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (1.0.8)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (1.7.3)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from Keras==2.2.4) (1.15.0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "2.]IMPORTING LIBRARIES TO BUILD MODEL.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#library to train the model\nimport keras\nimport tensorflow\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Convolution2D,MaxPooling2D, Flatten",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "3.]IMPORTING LIBRARIES FOR IMAGE AUGMENTATION.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#image augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,shear_range=0.2,horizontal_flip=True,vertical_flip=False)\ntest_datagen=ImageDataGenerator(rescale=1./255)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "4.]ADDING STREAMING_BODY_OBJECT FOR DATASET.ZIP",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='aqprHZFuH38ECUn869hHk4qyvS_iKJfrZAWUJJQ-mQKx',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'realtimecommunicationforspecially-donotdelete-pr-rfqndcvwgch6fu'\nobject_key = 'Dataset.zip'\n\nstreaming_body_4 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ls",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Dataset/  test_set/  training_set/\n5.]UNZIPPING THE DATASET",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_4.read()),'r')\nfile_paths=unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)\npwd",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'/home/wsuser/work/Dataset'\n#checking that the dataset is there are not\nimport os\nfilenamer = os.listdir('/home/wsuser/work/Dataset/training_set')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "6.]TRAINING AND TESTING IMAGES UNDER CLASSES",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "6.]TRAINING AND TESTING IMAGES UNDER CLASSES",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Found 15750 images belonging to 9 classes.\nx_test=test_datagen.flow_from_directory(\"/home/wsuser/work/Dataset/test_set\",target_size=(64,64),\nclass_mode='categorical' , batch_size=25)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "7.]TOTAL CLASSES UNDER TRAINING AND TESTING.\nx_train.class_indices",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_test.class_indices",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "train_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\ntest_datagen=ImageDataGenerator(rescale=1./255)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\n8.]MODEL BUILDING USING CNN",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model=Sequential()\n\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation='relu'))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.summary()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 30752)             0         \n=================================================================\nTotal params: 896\nTrainable params: 896\nNon-trainable params: 0",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "9.]ADDING LAYERS FOR MODEL TRAINING.\nHIDDEN LAYERS",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.add(Dense(units = 300, activation='relu'))\n#model.add(Dense(unit = 150,init = \"uniform\" activation='softmax'))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "OUTPUT LAYERS",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.add(Dense(units = 5, activation='softmax'))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "10.]OPTIMIZING THE MODEL",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "len(x_train)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "630",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "len(x_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "90",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "11.]FITTING THE MODEL",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#model.fit_generator(x_train,steps_per_epoch=len(x_train),validation_data=x_test,validation_steps=len(x_test),epochs=10)\n# Fitting the Model Generator\nmodel.fit_generator(x_train,steps_per_epoch=630,epochs=1,validation_data=x_test,validation_steps=90)\n#model.fit(x_train, epochs=100, verbose=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "--------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/tmp/wsuser/ipykernel_164/1479672656.py in \n      1 #model.fit_generator(x_train,steps_per_epoch=len(x_train),validation_data=x_test,validation_steps=len(x_test),epochs=10)\n      2 # Fitting the Model Generator\n----> 3 model.fit_generator(x_train,steps_per_epoch=630,epochs=1,validation_data=x_test,validation_steps=90)\n      4 #model.fit(x_train, epochs=100, verbose=1)\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\n   1964                   'will be removed in a future version. '\n   1965                   'Please use `Model.fit`, which supports generators.')\n-> 1966     return self.fit(\n   1967         generator,\n   1968         steps_per_epoch=steps_per_epoch,\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1187                 _r=1):\n   1188               callbacks.on_train_batch_begin(step)\n-> 1189               tmp_logs = self.train_function(iterator)\n   1190               if data_handler.should_sync:\n   1191                 context.async_wait()\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py in error_handler(*args, **kwargs)\n    151     except Exception as e:\n    152       filtered_tb = _process_traceback_frames(e.__traceback__)\n--> 153       raise e.with_traceback(filtered_tb) from None\n    154     finally:\n    155       del filtered_tb\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n     56   try:\n     57     ctx.ensure_initialized()\n---> 58     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n     59                                         inputs, attrs, num_outputs)\n     60   except core._NotOkStatusException as e:\n\nInvalidArgumentError:  logits and labels must be broadcastable: logits_size=[25,5] labels_size=[25,9]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at /opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:4889)\n]] [Op:__inference_train_function_2383]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/__main__.py\", line 3, in \n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/wsuser/ipykernel_164/3808038373.py\", line 3, in \n>>>     model.fit_generator(x_train,steps_per_epoch=630,epochs=1,validation_data=x_test,validation_steps=90)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1966, in fit_generator\n>>>     return self.fit(\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 1189, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 859, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 849, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 842, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\", line 800, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/compile_utils.py\", line 204, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/losses.py\", line 155, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/losses.py\", line 259, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/losses.py\", line 1679, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/backend.py\", line 4889, in categorical_crossentropy\n>>>     return nn.softmax_cross_entropy_with_logits_v2(\n>>> ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "12.]SAVING THE MODEL",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ls",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "pwd",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.save('Dataset.h5')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "13.]CONVERTING ZIP FILE TO TAR FILE FOR LOCAL USE.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#converting the model to tar\n!tar -zcvf image.Classification.model_new.tgz Dataset.h5",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ls -1",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Dataset/\nDataset.h5\nimage.Classification.model_new.tgz\ntest_set/\ntraining_set/",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "14.]INSTALLING WATSON MACHINE LEARNING CLIENT SOFTWARE\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#installing the machine learning repository\n!pip install watson_machine_learning_client --upgrade",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "Collecting watson_machine_learning_client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n     |████████████████████████████████| 538 kB 23.9 MB/s eta 0:00:01\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.3.4)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.3.3)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.26.7)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.26.0)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2022.9.24)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (4.62.3)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (1.18.21)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (0.8.9)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.5.0)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson_machine_learning_client) (0.10.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson_machine_learning_client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson_machine_learning_client) (2.11.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson_machine_learning_client) (3.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson_machine_learning_client) (1.20.3)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "15.]IMPORTING APICLIENT FOR DEPLOYING.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from ibm_watson_machine_learning import APIClient\nurl_credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": \"sqLVTXSP3nnAKfzJ1rKRKCpNzS_XZ8_HXa9FRwV7BvOP\"\n}\nclient = APIClient(url_credentials)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "client = APIClient(url_credentials)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "16.]CREATING API_CLIENT SPACE ID.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def guid_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "space_uid = guid_from_space_name(client, 'Image Classification')\nprint(\"space UID = \" + space_uid)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "space UID = d90f421e-9169-47e7-a58c-0e7bb0e65685",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "client.set.default_space(space_uid)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'SUCCESS'",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "client.software_specifications.list()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "NAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow\")\nsoftware_spec_uid",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "17.]STORING THE MODEL_ID FOR DATASET.H5",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#store the model\nmodel_details = client.repository.store_model(model='Image-classification-model_new.tgz',meta_props={\n    client.repository.ModelMetaNames.NAME:'CNN',\n    client.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid}\n                                             )\nmodel_id = client.repository.get_model_uid(model_details)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model_id",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.save('Dataset.h5')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "18.]DOWNLOADING THE TAR FILE ON CLIENT REPOSITORY",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "client.repository.download(model_id, 'my_model.tar.gz')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "19.]TEST THE MODEL",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom tensorflow.keras.models import load_model\nfrom keras.preprocessing import image",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "20.]LOADING THE DATASET",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Load the model\nmodel=load_model('Dataset.h5')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "21.]ADDING STREAMING_BODY FOR TEST IMAGE.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='aqprHZFuH38ECUn869hHk4qyvS_iKJfrZAWUJJQ-mQKx',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'realtimecommunicationforspecially-donotdelete-pr-rfqndcvwgch6fu'\nobject_key = '1.png'\n\nstreaming_body_5 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "22.]TESTING ON SEVERAL TESTING IMAGES",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img = image.load_img(streaming_body_5,target_size=(64, 64))\n#img=image.load_img(\"/home/wsuser/work/1\",target_size=(64,64))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "--------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n/tmp/wsuser/ipykernel_164/365554034.py in \n----> 1 img = image.load_img(streaming_body_5,target_size=(64, 64))\n      2 #img=image.load_img(\"/home/wsuser/work/1\",target_size=(64,64))\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras/preprocessing/image.py in load_img(path, grayscale, color_mode, target_size, interpolation)\n    311     ```python\n    312     (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n--> 313     y_train = np_utils.to_categorical(y_train, num_classes)\n    314     y_test = np_utils.to_categorical(y_test, num_classes)\n    315 \n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_preprocessing/image/utils.py in load_img(path, grayscale, color_mode, target_size, interpolation)\n    111         raise ImportError('Could not import PIL.Image. '\n    112                           'The use of `load_img` requires PIL.')\n--> 113     with open(path, 'rb') as f:\n    114         img = pil_image.open(io.BytesIO(f.read()))\n    115         if color_mode == 'grayscale':\n\nTypeError: expected str, bytes or os.PathLike object, not StreamingBody",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "ls",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img=image.load_img(r\"/home/wsuser/work/Dataset/test_set/A/1.png\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "FileNotFoundError                         Traceback (most recent call last)\n/tmp/wsuser/ipykernel_164/1035932264.py in \n----> 1 img=image.load_img(r\"/content/drive/MyDrive/IBM_PROJECT/Dataset/training_set/A/1.png\")\n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py in load_img(path, grayscale, color_mode, target_size, interpolation)\n    311       ValueError: if interpolation method is not supported.\n    312   \"\"\"\n--> 313   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n    314                         target_size=target_size, interpolation=interpolation)\n    315 \n\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/keras_preprocessing/image/utils.py in load_img(path, grayscale, color_mode, target_size, interpolation)\n    111         raise ImportError('Could not import PIL.Image. '\n    112                           'The use of `load_img` requires PIL.')\n--> 113     with open(path, 'rb') as f:\n    114         img = pil_image.open(io.BytesIO(f.read()))\n    115         if color_mode == 'grayscale':\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/IBM_PROJECT/Dataset/training_set/A/1.png'",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img1=image.load_ing(r\"/home/wsuser/work/Dataset/test_set/C/1.png\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img1",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x=image.img_to_array(img)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x1=np.expand_dims(x,axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x1",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "y=np.argmax(model.predoct(x),axis=1)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "y",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_train.class_indices",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "index=['A','B','C','D','E','F','G','H','I']\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "index[y[0]]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img=image.load_img(r\"/home/wsuser/work/Dataset/test_set/A/90.png\",target_size=(64,64))\nx=image.ing_to_array(img)\nx=np.expand_dims(x,axis=0)\ny=fnp.argmax(model.predict(x),axis=1)\nindex=['A','B','C','D','E','F','G','H','I']\nindex[y[0]]]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img=image.load_img( \"/home/wsuser/work/Dataset/test_set/D/1.png\",target_size=(64,64))\nx=image.ing_to_array(img)\nx=np.expand_dims(x,axis=0)\ny=np.argmax(model.predict(x)\nindex=['A','B','C','D','E','F','G','H','I']\nindex[y[0]]\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img=image.load_img(r\"/content/drive/MyDrive/IBM_PROJECT/Dataset/test_set/G/1.png\",target_size=(64,64))\nx=image.ing_to_array(img)\nx=np.expand_dims(x,axisme)\ny=np.argmax(model.predict(x), axis=1)\nindex=['A','B','C','D','E','F','G','H','I']\nindex[y[0]]\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "img=image.load_img(r\"/content/drive/MyDrive/IBM_PROJECT/Dataset/test_set/D/1.png\",target_size=(64,64))\nx-image.ing_to_array(img)\nx=np.expand_dims(x,axisme)\ny=np.argmax(model.predict(x), axis=1)\nindex=['A','B','C','D','E','F','G','H','I']\nindex[y[0]]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!tar -zcvf Dataset-classification-model.tgz specially.h5\nimport tensorflow as tf\ntf .__ _version_\n!pip install keras == 2.2.4",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "23.]IBM DEPLOYMENT",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!pip install watson-machine-learning-client  \nfrom ibm_watson_machine learning import APIClient\nwml_credentials={\n\"url\":\"https://us-south.ml.cloud.ibm.com\",\n\"apikey\":\"x91CJTUTrrIfLvrXsKf8yLyI1KHb3JV0Y7Qrwy1zilb2\"\n}\nclient=APIClient(wml_credentials)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "CLIENT\ndef guid_space_name(client,animal_deploy):\nspace-client.spaces.get_details()\nreturn(next(item for item in space[' resources'] if iten['entity']['name']= animal_deploy)[\"metadata']['id'])\nspace_uid-guid_space_name(client,'animal_deploy\")\nprint(\"Space UID \"+space_uid)\nclient.set.default_space(space_uid)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "client,software specifications.list(200)\nsoftware_space_uid=client.software_specifications.get_uid_by_name('tensorflow_rt22.1-py3.9¹)\nsoftware_space_uid\nmodel_details=client.repository.store_model(model='Dataset.tgz',meta_props={\nclient.repository.ModelMetaNames.NAME: \"CNN Model Building\",\nclient.repository.ModelMetaNames.TYPE: 'tensorflow_2.7',\nclient.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_space_uid\n})\nmodel_id=client.repository.get_model_id(model_details)\nmodel_id",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}